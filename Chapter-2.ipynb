{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5960f2a2",
   "metadata": {},
   "source": [
    "# Bab 2: End-to-End Machine Learning Project\n",
    "\n",
    "Bab ini akan memandu Anda melalui sebuah proyek pembelajaran mesin secara menyeluruh, dari tahap awal hingga akhir, menggunakan dataset **California Housing Prices**. Tujuan proyeknya adalah membangun model yang dapat memprediksi harga median rumah di sebuah distrik California.\n",
    "\n",
    "Langkah-langkah yang akan kita jalani:\n",
    "- **Melihat gambaran besar** proyek dan tujuan bisnis.\n",
    "- **Mengambil data** yang diperlukan untuk pelatihan.\n",
    "- **Menemukan dan memvisualisasikan data** untuk mendapatkan wawasan.\n",
    "- **Mempersiapkan data** untuk algoritma pembelajaran mesin.\n",
    "- **Memilih model** yang sesuai dan melatihnya.\n",
    "- **Menyempurnakan model** untuk meningkatkan kinerjanya.\n",
    "- **Menyajikan solusi** dan mengevaluasi sistem pada data uji.\n",
    "- **Meluncurkan, memantau, dan memelihara sistem** pembelajaran mesin.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Mendapatkan Data\n",
    "\n",
    "Langkah pertama adalah mengunduh dan memuat dataset. Kita akan membuat beberapa fungsi untuk mengotomatiskan proses ini agar rapi dan dapat digunakan kembali.\n",
    "\n",
    "```python\n",
    "# Menyiapkan environment\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lokasi download dan path penyimpanan data\n",
    "DOWNLOAD_ROOT = \"[https://raw.githubusercontent.com/ageron/handson-ml2/master/](https://raw.githubusercontent.com/ageron/handson-ml2/master/)\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# Fungsi untuk mengunduh dan mengekstrak data\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "# Menjalankan fungsi download\n",
    "fetch_housing_data()\n",
    "\n",
    "# Fungsi untuk memuat data CSV ke dalam pandas DataFrame\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Menemukan dan Memvisualisasikan Data untuk Mendapatkan Wawasan\n",
    "\n",
    "Setelah data dimuat, kita perlu melihat struktur, ringkasan statistik, dan visualisasinya untuk mendapatkan pemahaman awal.\n",
    "\n",
    "``` python\n",
    "# Menampilkan 5 baris pertama\n",
    "print(\"Lima baris pertama:\")\n",
    "print(housing.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Menampilkan informasi ringkas (tipe data, nilai non-null)\n",
    "print(\"Informasi dataset:\")\n",
    "housing.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Melihat ringkasan statistik fitur numerik\n",
    "print(\"Deskripsi statistik:\")\n",
    "print(housing.describe())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Melihat distribusi data dengan histogram\n",
    "print(\"Distribusi data (Histogram):\")\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi geografis data\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1,\n",
    "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "             sharex=False)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Membuat Test Set (Stratified Sampling)\n",
    "Penting untuk menyisihkan test set sejak awal untuk mencegah data snooping bias. Kita akan menggunakan stratified sampling berdasarkan kategori pendapatan (median_income) untuk memastikan test set kita representatif terhadap keseluruhan data.\n",
    "\n",
    "``` python\n",
    "# Membuat kategori pendapatan untuk stratified sampling\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# Menghapus kolom income_cat karena hanya digunakan untuk splitting\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "# Membuat salinan data training untuk eksplorasi dan persiapan\n",
    "housing = strat_train_set.copy()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Mempersiapkan Data (Preprocessing Pipeline)\n",
    "Tahap ini krusial, di mana kita membersihkan dan mentransformasi data agar siap digunakan oleh model. Kita akan membangun sebuah pipeline untuk menangani fitur numerik dan kategorikal secara terpisah dan terstruktur.\n",
    "``` python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Memisahkan fitur dari label pada data training\n",
    "housing_labels = housing[\"median_house_value\"].copy()\n",
    "housing_features = housing.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "# Mengambil nama kolom numerik dan kategorikal\n",
    "housing_num_attribs = housing_features.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num_attribs)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "# Pipeline untuk fitur numerik: mengisi nilai kosong dengan median & menstandardisasi skala\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# Pipeline penuh yang menggabungkan proses untuk fitur numerik dan kategorikal\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "# Menjalankan pipeline pada data training\n",
    "housing_prepared = full_pipeline.fit_transform(housing_features)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Memilih dan Melatih Model\n",
    "Kita akan melatih beberapa model dan mengevaluasinya menggunakan cross-validation untuk memilih kandidat model terbaik. Di sini kita contohkan dengan RandomForestRegressor.\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Inisialisasi model\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Evaluasi model menggunakan cross-validation (10-fold)\n",
    "# Kita gunakan scoring 'neg_mean_squared_error', lalu akarkan untuk mendapatkan RMSE\n",
    "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "print(\"Hasil Evaluasi RandomForestRegressor:\")\n",
    "display_scores(rmse_scores)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Menyempurnakan Model (Fine-Tuning)\n",
    "Setelah memilih model dengan potensi terbaik, kita mencari kombinasi hyperparameter optimal menggunakan GridSearchCV.\n",
    "``` python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definisikan grid hyperparameter yang akan diuji\n",
    "param_grid = [\n",
    "    # Coba kombinasi n_estimators dan max_features\n",
    "    {'n_estimators': [10, 30, 50], 'max_features': [6, 8, 10]},\n",
    "    # Coba kombinasi lain dengan bootstrap=False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Menjalankan grid search\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Menampilkan hyperparameter terbaik\n",
    "print(\"Hyperparameter terbaik:\", grid_search.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Evaluasi Akhir pada Test Set\n",
    "Ini adalah langkah terakhir dalam evaluasi. Kita menggunakan test set yang telah kita sisihkan sejak awal untuk mengukur kinerja model final yang sudah disempurnakan.\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Model terbaik dari Grid Search\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Memisahkan fitur dan label dari test set\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "# Menjalankan pipeline pada test set (HANYA transform, bukan fit_transform!)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "# Membuat prediksi\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "# Menghitung RMSE final\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"\\nRMSE final pada test set:\", final_rmse)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Meluncurkan, Memantau, dan Memelihara Sistem\n",
    "Setelah model dianggap memuaskan, langkah selanjutnya adalah menyimpannya untuk digunakan di lingkungan produksi. Anda perlu memantau kinerjanya secara berkala dan mungkin melatihnya kembali dengan data baru.\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Menyimpan model final dan pipeline untuk penggunaan selanjutnya\n",
    "joblib.dump(final_model, 'final_model.pkl')\n",
    "joblib.dump(full_pipeline, 'full_pipeline.pkl')\n",
    "\n",
    "# Contoh cara memuat kembali dan menggunakan model\n",
    "# model_loaded = joblib.load('final_model.pkl')\n",
    "# pipeline_loaded = joblib.load('full_pipeline.pkl')\n",
    "# new_data_prepared = pipeline_loaded.transform(new_data)\n",
    "# new_predictions = model_loaded.predict(new_data_prepared)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
