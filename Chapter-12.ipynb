{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3c3cc4",
   "metadata": {},
   "source": [
    "# Bab 12: Custom Models and Training with TensorFlow\n",
    "\n",
    "### 1. Pendahuluan\n",
    "\n",
    "Bab 12 membawa kita lebih dalam ke dunia TensorFlow, melampaui API tingkat tinggi Keras yang telah kita gunakan sejauh ini. Meskipun Keras sangat kuat dan mudah digunakan, terkadang kita memerlukan fleksibilitas lebih untuk membangun arsitektur yang tidak biasa, membuat *loss function* kustom, atau bahkan menulis *training loop* sendiri. Bab ini akan menunjukkan bagaimana cara bekerja dengan API tingkat rendah TensorFlow.\n",
    "\n",
    "Topik yang akan dibahas meliputi:\n",
    "* **Dasar-dasar TensorFlow:** Bekerja dengan *tensors* dan operasi-operasi dasar.\n",
    "* **Kustomisasi:**\n",
    "    * Membuat *loss function* dan metrik kustom.\n",
    "    * Membuat *layer* dan model kustom dengan *subclassing*.\n",
    "    * Menulis *training loop* kustom dari awal.\n",
    "* **Performa:** Bagaimana TensorFlow mengubah fungsi Python menjadi graf komputasi berperforma tinggi menggunakan `tf.function`.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Sekilas tentang TensorFlow\n",
    "\n",
    "TensorFlow adalah *library* yang kuat untuk komputasi numerik, khususnya untuk *machine learning* skala besar. Unit data fundamental di TensorFlow adalah **tensor**, yang sangat mirip dengan NumPy `ndarray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fc46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t:\n",
      " tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "Indexing t[:, 1:]: tf.Tensor(\n",
      "[[2. 3.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "t + 10: tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "tf.square(t): tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "Tensor dari NumPy: tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
      "NumPy dari Tensor: [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Membuat Tensor\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
    "print(\"Tensor t:\\n\", t)\n",
    "\n",
    "# Indexing\n",
    "print(\"\\nIndexing t[:, 1:]:\", t[:, 1:])\n",
    "\n",
    "# Operasi Tensor\n",
    "print(\"\\nt + 10:\", t + 10)\n",
    "print(\"tf.square(t):\", tf.square(t))\n",
    "\n",
    "# Tensor dan NumPy\n",
    "# Konversi dari NumPy array ke Tensor\n",
    "a = np.array([2., 4., 5.])\n",
    "b = tf.constant(a)\n",
    "print(\"\\nTensor dari NumPy:\", b)\n",
    "\n",
    "# Konversi dari Tensor ke NumPy array\n",
    "print(\"NumPy dari Tensor:\", t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b275ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Kustomisasi Model dan Algoritma Pelatihan\n",
    "Walaupun Keras menyediakan banyak komponen siap pakai, fleksibilitas TensorFlow memungkinkan kita untuk mengkustomisasi hampir setiap bagian dari model.\n",
    "\n",
    "### a. Custom Loss Functions\n",
    "Membuat loss function kustom di Keras sangatlah mudah. Cukup buat sebuah fungsi yang menerima y_true (label sebenarnya) dan y_pred (prediksi) sebagai argumen, lalu gunakan operasi TensorFlow untuk menghitung loss.\n",
    "\n",
    "Berikut adalah contoh implementasi Huber loss, yang tidak sensitif terhadap outlier besar.\n",
    "$$ \\text{Huber}(y, \\hat{y}, \\delta) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2}(y - \\hat{y})^2 & \\text{if } |y - \\hat{y}| \\le \\delta \\\n",
    "\\delta(|y - \\hat{y}| - \\frac{1}{2}\\delta) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114fd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Huber loss kustom\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# Contoh penggunaan pada model Keras\n",
    "# model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
    "# model.fit(X_train, y_train, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84916ff",
   "metadata": {},
   "source": [
    "### b. Custom Layers\n",
    "Untuk arsitektur yang eksotis atau layer yang tidak biasa, Anda dapat membuat layer kustom sendiri dengan membuat subclass dari keras.layers.Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35eda2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b253b09",
   "metadata": {},
   "source": [
    "### c. Custom Models\n",
    "Mirip dengan layer, Anda dapat membuat model dengan arsitektur yang sangat fleksibel dengan membuat subclass dari keras.Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dbbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        # ... implementasi block (misalnya, untuk ResNet)\n",
    "        pass\n",
    "    def call(self, inputs):\n",
    "        # ...\n",
    "        pass\n",
    "\n",
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Definisikan layer-layer di sini\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Definisikan alur forward pass di sini\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1, 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ddd8db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Custom Training Loops\n",
    "Menulis training loop kustom memberikan kontrol penuh atas proses pelatihan. Ini berguna untuk penelitian atau saat ingin mencoba ide-ide baru yang tidak didukung oleh metode .fit() bawaan.\n",
    "\n",
    "Prosesnya secara umum adalah:\n",
    "\n",
    "1. Buat nested loop: satu untuk epoch, satu lagi untuk batch di dalam setiap epoch.\n",
    "2. Di dalam loop batch, buat tf.GradientTape() context.\n",
    "3. Lakukan forward pass di dalam context tersebut untuk membuat prediksi.\n",
    "4. Hitung loss berdasarkan prediksi dan label sebenarnya.\n",
    "5. Gunakan tape untuk menghitung gradien dari loss terhadap setiap trainable variable model.\n",
    "6. Terapkan gradien ini pada variable menggunakan optimizer untuk memperbarui bobot.\n",
    "7. Perbarui metrik, cetak status, dan ulangi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24b8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Asumsikan model, optimizer, loss_fn, dan dataset sudah didefinisikan)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(batch_size)\n",
    "# mean_loss = keras.metrics.Mean()\n",
    "# metrics = [keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "# for epoch in range(1, n_epochs + 1):\n",
    "#     print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "#     for X_batch, y_batch in dataset:\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             y_pred = model(X_batch, training=True)\n",
    "#             main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "#             loss = tf.add_n([main_loss] + model.losses)\n",
    "        \n",
    "#         gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#         optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "#         # Update metrics\n",
    "#         mean_loss(loss)\n",
    "#         for metric in metrics:\n",
    "#             metric(y_batch, y_pred)\n",
    "#     print(f\"  loss: {mean_loss.result():.4f}\", end=\"\")\n",
    "#     for metric in metrics:\n",
    "#         print(f\" - {metric.name}: {metric.result():.4f}\", end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96b2a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. TensorFlow Functions dan Graphs\n",
    "Performa Python tidak secepat C++. Untuk mengatasinya, TensorFlow dapat mengubah fungsi Python menjadi graf komputasi berperforma tinggi. Ini dilakukan dengan membungkus fungsi tersebut dalam tf.function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53d406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Python biasa\n",
    "def cubed(x):\n",
    "    return x ** 3\n",
    "\n",
    "# Diubah menjadi TensorFlow Function\n",
    "tf_cubed = tf.function(cubed)\n",
    "\n",
    "# Atau menggunakan decorator\n",
    "@tf.function\n",
    "def tf_cubed_decorated(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cdff0",
   "metadata": {},
   "source": [
    "Saat Anda memanggil tf.function untuk pertama kalinya, ia akan \"menelusuri\" (trace) fungsi tersebut, menganalisis semua operasi TensorFlow, dan membangun graf komputasi yang setara. Setelah itu, TensorFlow akan mengeksekusi graf yang sudah dioptimalkan ini, yang jauh lebih cepat daripada mengeksekusi kode Python baris per baris. Keras secara otomatis melakukan ini untuk model Anda saat Anda memanggil .fit().\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Kesimpulan\n",
    "Bab ini menunjukkan kekuatan dan fleksibilitas TensorFlow di luar API tingkat tinggi Keras. Dengan kemampuan untuk membuat layer, loss, model, dan bahkan training loop kustom, Anda memiliki alat yang diperlukan untuk mengimplementasikan hampir semua arsitektur deep learning, bahkan yang paling baru sekalipun. Memahami tf.function juga penting untuk memastikan kode kustom Anda berjalan seefisien mungkin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
