{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82dc50c",
   "metadata": {},
   "source": [
    "# Bab 17: Autoencoders and GANs (Autoencoder dan GAN)\n",
    "\n",
    "### 1. Pendahuluan\n",
    "\n",
    "Bab 17 membahas dua keluarga arsitektur *Neural Network* yang sangat menarik dan kuat dalam kategori *unsupervised learning* atau *generative models*: **Autoencoders** dan **Generative Adversarial Networks (GANs)**. Kedua jenis model ini berfokus pada pembelajaran representasi data (*representation learning*) dan/atau generasi data baru yang realistis (*generative learning*).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Autoencoders (Autoencoder)\n",
    "\n",
    "*Autoencoder* adalah Jaringan Saraf Tiruan yang dilatih untuk menghasilkan output yang hampir identik dengan inputnya. Ini mungkin terdengar tidak berguna, tetapi *Autoencoder* tidak hanya sekadar menyalin; mereka dilatih untuk melakukannya di bawah beberapa kendala, yang memaksa mereka untuk mempelajari representasi data yang efisien.\n",
    "\n",
    "#### a. Arsitektur Autoencoder\n",
    "Sebuah *Autoencoder* umumnya terdiri dari dua bagian:\n",
    "* **Encoder:** Memetakan data input ke representasi berdimensi lebih rendah (disebut *codings* atau *latent representation*).\n",
    "* **Decoder:** Merekonstruksi data asli dari *codings*.\n",
    "\n",
    "Kendala yang diterapkan (misalnya, dimensi *coding* yang lebih rendah) mencegah *Autoencoder* untuk hanya menjiplak input, memaksanya untuk belajar fitur-fitur penting.\n",
    "\n",
    "#### b. Stacked Autoencoders (Autoencoder Bertumpuk)\n",
    "*Autoencoder* dengan beberapa *hidden layer* disebut *Stacked Autoencoder*. Menambahkan lebih banyak lapisan membantu model mempelajari representasi yang lebih kompleks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a126449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khalif Prawira\\AppData\\Local\\Programs\\Orange\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\Khalif Prawira\\AppData\\Local\\Programs\\Orange\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Membangun Stacked Autoencoder untuk Fashion MNIST\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"), # Lapisan codings\n",
    "])\n",
    "\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "# Mengompilasi dengan loss binary_crossentropy karena output piksel antara 0 dan 1\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
    "\n",
    "# (Kode untuk memuat data dan melatih model akan mengikuti pola yang sama\n",
    "# seperti pada bab-bab sebelumnya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa348b1",
   "metadata": {},
   "source": [
    "### c. Denoising Autoencoders (Autoencoder Penghilang Noise)\n",
    "Dengan menambahkan noise pada input dan melatih model untuk merekonstruksi input asli yang bersih, Denoising Autoencoder dipaksa untuk mempelajari fitur-fitur yang lebih robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3ca5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan lapisan Dropout pada input untuk simulasi noise\n",
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),  # Coding layer to match decoder input\n",
    "])\n",
    "\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    # ...\n",
    "])\n",
    "\n",
    "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39873b50",
   "metadata": {},
   "source": [
    "### d. Variational Autoencoders (VAE)\n",
    "VAE adalah generative autoencoder, yang berarti selain dapat mengompresi dan merekonstruksi data, ia juga dapat menghasilkan sampel baru yang terlihat seperti data pelatihan. VAE melakukannya dengan mempelajari distribusi probabilitas dari data laten, bukan hanya satu titik coding.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Generative Adversarial Networks (GANs)\n",
    "GANs adalah pendekatan yang sangat berbeda untuk pemodelan generatif. Arsitektur ini terdiri dari dua jaringan yang \"bersaing\" satu sama lain:\n",
    "\n",
    "* **Generator**: Bertugas menghasilkan data palsu (misalnya, gambar) yang terlihat serealistis mungkin.\n",
    "* **Discriminator**: Bertugas membedakan antara data asli dan data palsu yang dihasilkan oleh generator.\n",
    "Selama pelatihan, keduanya menjadi lebih baik dalam tugas mereka masing-masing. Generator belajar menghasilkan gambar yang semakin sulit dibedakan, sementara discriminator menjadi semakin ahli dalam mendeteksi kepalsuan. Keseimbangan ini (disebut Nash equilibrium) menghasilkan generator yang mampu membuat data yang sangat realistis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a52b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerangka implementasi GAN sederhana untuk Fashion MNIST\n",
    "codings_size = 30\n",
    "\n",
    "# Generator\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "# Discriminator\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Model GAN yang menggabungkan keduanya\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "# Mengompilasi model\n",
    "# Discriminator dilatih secara terpisah\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "# Generator dilatih melalui model GAN, di mana discriminator dibekukan\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a4c26",
   "metadata": {},
   "source": [
    "### a. Tantangan Pelatihan GAN\n",
    "Pelatihan GAN terkenal sulit karena menemukan Nash equilibrium antara generator dan discriminator sangatlah rumit. Jika salah satu menjadi terlalu kuat, pelatihan bisa gagal.\n",
    "\n",
    "### b. Deep Convolutional GAN (DCGAN)\n",
    "Untuk menghasilkan gambar yang lebih realistis dan beresolusi lebih tinggi, digunakan arsitektur DCGAN. Kunci utamanya adalah menggunakan lapisan konvolusional pada generator (disebut transposed convolutions untuk upsampling) dan discriminator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
