{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0d827a",
   "metadata": {},
   "source": [
    "# Bab 3: Classification\n",
    "\n",
    "## 1. Pendahuluan\n",
    "\n",
    "Bab ini berfokus pada sistem klasifikasi, yang merupakan salah satu tugas utama dalam pembelajaran terawasi (*supervised learning*) selain regresi. Dalam bab ini, konsep-konsep dasar klasifikasi dijelaskan secara mendalam, terutama dengan menggunakan dataset MNIST yang populer.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Dataset MNIST\n",
    "\n",
    "Dataset MNIST diperkenalkan sebagai \"hello world\" di dunia Machine Learning untuk tugas klasifikasi. Dataset ini terdiri dari 70.000 gambar kecil tulisan tangan digit (0-9), dengan setiap gambar berukuran 28x28 piksel dan memiliki 784 fitur (intensitas piksel dari 0 hingga 255). Dataset ini sudah dibagi menjadi 60.000 gambar untuk training dan 10.000 gambar untuk testing.\n",
    "\n",
    "Pertama, kita muat dataset MNIST. `keras` menyediakan fungsi praktis untuk ini.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Memuat dataset MNIST\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Mengubah gambar 28x28 menjadi vektor 1D berukuran 784\n",
    "X_train = X_train_full.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "# Normalisasi data (opsional, tetapi sering membantu)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "y_train = y_train_full\n",
    "\n",
    "# Tampilkan salah satu digit\n",
    "some_digit_img = X_train[0].reshape(28, 28)\n",
    "plt.imshow(some_digit_img, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3 Melatih Pengklasifikasi Biner (Binary Classifier)\n",
    "\n",
    "Konsep klasifikasi biner dijelaskan dengan contoh \"pendeteksi angka 5\", di mana tujuannya adalah membedakan gambar angka 5 dari bukan angka 5. Untuk tugas ini, digunakan pengklasifikasi Stochastic Gradient Descent (SGDClassifier) dari Scikit-Learn. SGDClassifier dipilih karena kemampuannya menangani dataset yang sangat besar secara efisien.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Membuat label target untuk klasifikasi biner (True untuk 5, False untuk lainnya)\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# Membuat dan melatih model SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Menguji pada satu instance (digit pertama, yaitu angka 5)\n",
    "some_digit = X_train[0]\n",
    "print(f\"Prediksi untuk digit pertama (seharusnya True): {sgd_clf.predict([some_digit])}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Pengukuran Kinerja (Perfomance Measures)\n",
    "\n",
    "Evaluasi kinerja pengklasifikasi adalah bagian penting, mengingat bahwa akurasi saja seringkali bukan metrik yang memadai, terutama untuk dataset yang tidak seimbang (skewed dataset).\n",
    "\n",
    "**Akurasi Menggunakan Validasi silang (Cross- Validation)**\n",
    "\n",
    "Akurasi saja bisa menipu. Sebagai contoh, pengklasifikasi \"bodoh\" yang selalu memprediksi \"bukan angka 5\" bisa mencapai akurasi 90% pada dataset MNIST, karena hanya sekitar 10% data yang merupakan angka 5.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Mengukur akurasi SGDClassifier\n",
    "accuracy_sgd = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Akurasi SGD Classifier: {accuracy_sgd}\")\n",
    "\n",
    "# Contoh \"pengklasifikasi bodoh\"\n",
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "accuracy_dumb = cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(f\"Akurasi 'Never 5' Classifier: {accuracy_dumb}\")\n",
    "```\n",
    "\n",
    "**Confusion Matrix**\n",
    "\n",
    "Confusion Matrix adalah cara yang lebih baik untuk mengevaluasi kinerja. Matriks ini menghitung berapa kali instance dari kelas A diklasifikasikan sebagai kelas B. Istilah kunci:\n",
    "* True Negative (TN): Instance negatif yang diprediksi dengan benar.\n",
    "* False Positive (FP): Instance negatif yang salah diprediksi sebagai positif.\n",
    "* False Negative (FN): Instance positif yang salah diprediksi sebagai negatif.\n",
    "* True Positive (TP): Instance positif yang diprediksi dengan benar.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Mendapatkan prediksi untuk setiap instance di training set\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "# Menghitung confusion matrix\n",
    "cm = confusion_matrix(y_train_5, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "```\n",
    "\n",
    "**Presisi (Precision) dan Recall**\n",
    "\n",
    "Dua metrik penting dari Confusion matrix:\n",
    "* Precision (Presisi): Akurasi dari prediksi positif (TP / (TP + FP)). Menjawab pertanyaan: \"Dari semua yang diprediksi sebagai kelas positif, berapa persen yang benar?\"\n",
    "* Recall (Sensitivitas): Rasio instance positif yang berhasil dideteksi oleh model (TP / (TP + FN)). Menjawab pertanyaan: \"Dari semua instance positif yang sebenarnya, berapa persen yang berhasil terdeteksi?\"\n",
    "* F1 Score: Rata-rata harmonik dari precision dan recall, berguna untuk membandingkan model yang memiliki presisi dan recall seimbang.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision:\", precision_score(y_train_5, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_train_5, y_train_pred))\n",
    "print(\"F1 Score:\", f1_score(y_train_5, y_train_pred))\n",
    "```\n",
    "\n",
    "**Trade-off Presisi/Recall**\n",
    "\n",
    "Tidak mungkin memiliki presisi dan recall yang tinggi secara bersamaan; meningkatkan satu akan mengurangi yang lain. Hal ini dipengaruhi oleh decision threshold yang digunakan model. Dengan mengubah threshold, kita bisa mengatur trade-off ini.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Mendapatkan decision scores alih-alih prediksi\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "# Menghitung presisi dan recall untuk berbagai threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"center left\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Precision and Recall vs. Decision Threshold\")\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Kurva ROC (Receiver Operating Characteristic)**\n",
    "\n",
    "Kurva ROC adalah metrik evaluasi populer lainnya. Kurva ini memplot True Positive Rate (Recall) melawan False Positive Rate (FPR). Metrik Area Under the Curve (AUC) sering digunakan untuk membandingkan model. AUC = 1 untuk model sempurna, dan AUC = 0.5 untuk model acak.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Menghitung FPR, TPR untuk berbagai threshold\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Garis putus-putus untuk pengklasifikasi acak\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "# Menghitung Area Under the Curve (AUC)\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_train_5, y_scores))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Klasifikasi Multikelas (Multiclass Classification)\n",
    "\n",
    "Sekarang kita akan melatih model untuk mengklasifikasikan semua 10 digit. Beberapa algoritma (seperti SGDClassifier, SVC) secara otomatis menggunakan strategi One-versus-Rest (OvR) atau One-versus-One (OvO) ketika dihadapkan pada tugas multikelas.\n",
    "\n",
    "```python\n",
    "# Melatih pada semua 10 kelas (menggunakan y_train, bukan y_train_5)\n",
    "# SGDClassifier secara otomatis menjalankan OvR\n",
    "sgd_clf.fit(X_train, y_train) \n",
    "print(\"Prediksi untuk digit pertama (seharusnya 5):\", sgd_clf.predict([some_digit]))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Analisis Kesalahan (Error Analysis)\n",
    "\n",
    "Menganalisis jenis kesalahan yang dibuat model dapat membantu kita memperbaikinya. Kita bisa memvisualisasikan confusion matrix untuk melihat pola kesalahan.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling dapat meningkatkan performa\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Mendapatkan prediksi multikelas\n",
    "y_train_pred_multi = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "\n",
    "# Membuat confusion matrix multikelas\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred_multi)\n",
    "print(\"Confusion Matrix Multikelas:\\n\", conf_mx)\n",
    "\n",
    "# Visualisasi confusion matrix\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.title(\"Multiclass Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Fokus pada error: normalisasi confusion matrix dan isi diagonal dengan nol\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.title(\"Normalized Error Matrix\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Visualisasi matriks error di atas menunjukkan pasangan angka mana yang sering salah diklasifikasikan (area yang lebih terang).\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Klasifikikasi Multilabel (Multilabel Classification)\n",
    "\n",
    "Ini adalah konsep di mana pengklasifikasi dapat menghasilkan beberapa kelas untuk satu instance (misalnya, mengenali beberapa orang dalam satu gambar).\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Contoh: label ganda untuk \"angka besar\" (>=7) dan \"angka ganjil\"\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "print(\"Prediksi multilabel untuk digit pertama (5):\", knn_clf.predict([some_digit]))\n",
    "# Output: [[False, True]] -> Bukan angka besar, tapi angka ganjil\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Klasifikasi Multioutput (Multioutput Classification)\n",
    "\n",
    "Ini adalah generalisasi dari klasifikasi multilabel di mana setiap label bisa bersifat multikelas (memiliki lebih dari dua nilai yang mungkin). Contohnya adalah sistem penghilang noise dari gambar, di mana setiap piksel adalah label.\n",
    "\n",
    "```python\n",
    "# Menambahkan noise ke gambar MNIST\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise / 255.0\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise / 255.0\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n",
    "\n",
    "# Melatih classifier untuk membersihkan noise\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[0]])\n",
    "\n",
    "# Fungsi untuk plot\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Tampilkan gambar asli, gambar bernoise, dan gambar yang sudah dibersihkan\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(131); plot_digit(X_test_mod[0]); plt.title(\"Noisy\")\n",
    "plt.subplot(132); plot_digit(clean_digit); plt.title(\"Cleaned\")\n",
    "plt.subplot(133); plot_digit(y_test_mod[0]); plt.title(\"Original\")\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
